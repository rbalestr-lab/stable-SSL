
data:
  train_on: base
  base:
    name: CIFAR10
    batch_size: 32
    drop_last: True
    shuffle: True
    split: train
    transforms:
      - view1:
        - name: RandomResizedCrop
          kwargs:
            scale: (0.1,0.2)
          p: 1.0
        - name: RandomHorizontalFlip
        - name: GaussianBlur
          kwargs:
            kernel_size: 5
          p: 0.2
      - view2:
        - name: RandomResizedCrop
          kwargs:
            scale: (0.1,0.2)
          p: 1.0
        - name: RandomHorizontalFlip
  test_in:
    name: CIFAR10
    batch_size: 32
    drop_last: False
    split: test
  test_out:
    name: SVHN
    batch_size: 32
    drop_last: False
    split: test


model:
  model: Supervised
  backbone_model: resnet9

optim:
  epochs: 100
  batch_size: 256
  lr: 1.0
  optimizer: LARS

log:
  folder: "./new_logs"
  project: "supervised_cifar10"

hardware:
  seed: 0
  float16: true
  gpu_id: 0
  world_size: 1
  # launcher: torch_distributed
  # cpus_per_task: 1
  # gpus_per_task: 1
  # tasks_per_node: 1
  # timeout_min: 60
  # partition: gpu
  # mem_gb: 30
